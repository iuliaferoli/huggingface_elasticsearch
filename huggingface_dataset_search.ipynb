{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Elasticsearch to explore Huggingface Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting from a HuggingFace dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface allows as to quickly get started with datasets. This collection of 2 million posts from blueskye will allow us to explore the text social media data and find some cool insights. \n",
    "\n",
    "https://huggingface.co/datasets/alpindale/two-million-bluesky-posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iulia/Documents/search options/search_options/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"alpindale/two-million-bluesky-posts\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [\"This is really interesting polling data about national public attitudes re: California.  It's from the LA Times, in January.  I wonder if this will change substantially in the next two years?  5233025.fs1.hubspotusercontent-na1.net/hubfs/523302...\"],\n",
       " 'created_at': ['2024-11-27T07:53:47.202Z'],\n",
       " 'author': ['did:plc:5ug6fzthlj6yyvftj3alekpj'],\n",
       " 'uri': ['at://did:plc:5ug6fzthlj6yyvftj3alekpj/app.bsky.feed.post/3lbw33zxvik24'],\n",
       " 'has_images': [False],\n",
       " 'reply_to': [None]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most interesting thing we can do with such a dataset is to search through the posts. Huggingface integrates seamlessly with elasticsearch to allow us to add search capabilities to the data. \n",
    "\n",
    "[These docs](https://huggingface.co/docs/datasets/en/faiss_es#elasticsearch) show how to add a search index to your Dataset.\n",
    "\n",
    "We can first connect to our cloud hosted ES client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass  \n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Prompt the user to enter their Elastic Cloud ID and API Key securely\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "ELASTIC_API_KEY = getpass(\"Elastic API Key: \")\n",
    "\n",
    "# Create an Elasticsearch client using the provided credentials\n",
    "client = Elasticsearch(\n",
    "    cloud_id=ELASTIC_CLOUD_ID,  # cloud id can be found under deployment management\n",
    "    api_key=ELASTIC_API_KEY, # your username and password for connecting to elastic, found under Deplouments - Security\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we now build an index out of our dataset to leverage for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2107530/2107530 [08:13<00:00, 4270.93docs/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'created_at', 'author', 'uri', 'has_images', 'reply_to'],\n",
       "    num_rows: 2107530\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name=\"bluesky\"\n",
    "ds.add_elasticsearch_index(column=\"text\", es_client=client ,es_index_name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This created the \"bluesky\" index in Elasticsearch and added our HuggingFace dataset to it. It also creates an index on the \"text\" feature of our Huggingface dataset that can be further leveraged.\n",
    "\n",
    "Once the index has been initialized once, you can load it again for future uses from elastic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.load_elasticsearch_index(\"text\", es_client=client ,es_index_name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now quickly run some searches!\n",
    "It feels like one of the most talked about topics on bluesky (at least from what my feed looks like lately) is people discussing twitter. Let's test that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Who’s here from Twitter? #x #twitter',\n",
       " \"you can take the twitter user out of twitter but you can't take twitter out of the twitter user\",\n",
       " 'Deixem os tópicos do Twitter no Twitter',\n",
       " '>opens twitter\\n>holocaust_denial.mp3\\n>closes twitter\\n>deletes app',\n",
       " 'Twitter failed to scare legacy verified accounts into paying for Twitter Blue https://mashable.com/article/twitter-legacy-verified-account-twitter-blue-subscribers']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, retrieved_examples = ds.get_nearest_examples(index_name=\"text\", query=\"twitter\", k=5)\n",
    "retrieved_examples[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if people on bluesky are talking about HuggingFace, or maybe our elasticon conference that happened last week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's huggingface?\n",
      "\n",
      "Huggingface, nomen est omen\n",
      "\n",
      "huggingface is drunk. damn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores, retrieved_examples = ds.get_nearest_examples(index_name=\"text\", query=\"huggingface\", k=3)\n",
    "for response in retrieved_examples[\"text\"]:\n",
    "    print(response + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "following the success of the community track at #ElasticON (here amsterdam from yesterday): we still have paris, london, singapore, and sydney coming up and are looking for community talks. send us your best tech topics around anything #elastic\n",
      "https://sessionize.com/elasticon\n",
      "\n",
      "Attended ElasticOn yesterday in Amsterdam. And learned about Better Binary Quantization (BBQ), which recently got implemented in Elastic and Lucene. Based of RaBitQ paper. Very interesting for everybody busy with vector search and RAG systems. www.elastic.co/search-labs/...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores, retrieved_examples = ds.get_nearest_examples(index_name=\"text\", query=\"elasticon\", k=3)\n",
    "for response in retrieved_examples[\"text\"]:\n",
    "    print(response + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just from these examples we can already think of what next steps would be interesting to explore. \n",
    "\n",
    "Perhaps checking the sentiment along with each query to see how people feel about a topic? \n",
    "\n",
    "Or using a multilingual model to help us work through the international posts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go beyond simple search by also leveraging models from the HuggingFace model hub to generate more insights for our queries.\n",
    "\n",
    "Let's start out with sentiment! For this task we can use [this classification model](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment) trained on tweets which we can expect to work quite well since our data type will be quite similar.\n",
    "\n",
    "These are the labels it should generate:\n",
    "\n",
    "Labels: 0 -> Negative; 1 -> Neutral; 2 -> Positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.955704927444458},\n",
       " {'label': 'LABEL_0', 'score': 0.9654269218444824}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe([\"I love you\", \"I hate you\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty legitimate. Let's try it on some of our previous sarch results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who’s here from Twitter? #x #twitter\n",
      "[{'label': 'LABEL_1', 'score': 0.8716976642608643}]\n",
      "\n",
      "you can take the twitter user out of twitter but you can't take twitter out of the twitter user\n",
      "[{'label': 'LABEL_1', 'score': 0.4940926432609558}]\n",
      "\n",
      "Deixem os tópicos do Twitter no Twitter\n",
      "[{'label': 'LABEL_1', 'score': 0.7995824813842773}]\n",
      "\n",
      ">opens twitter\n",
      ">holocaust_denial.mp3\n",
      ">closes twitter\n",
      ">deletes app\n",
      "[{'label': 'LABEL_1', 'score': 0.5307735800743103}]\n",
      "\n",
      "Twitter failed to scare legacy verified accounts into paying for Twitter Blue https://mashable.com/article/twitter-legacy-verified-account-twitter-blue-subscribers\n",
      "[{'label': 'LABEL_0', 'score': 0.6615949273109436}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores, retrieved_examples = ds.get_nearest_examples(index_name=\"text\", query=\"twitter\", k=5)\n",
    "for result in retrieved_examples[\"text\"]:\n",
    "    print(result)\n",
    "    print(pipe(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we seem to be getting mostly \"neutral\" results with low confidence in the classification. Perhaps we should dig deeper into our data to fish out some more sentimentally \"intense\" posts. Here's where the Elastic index will come in handy to help us build a more complex search use case. \n",
    "\n",
    "\n",
    "First off, we should apply this new sentiment insight to all our posts and add the results as a new feature in our index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second notebook we will leverage the elasticsearch python clients to deploy the model in our Elastic cluster, and set up an inference pipeline that adds the sentiment label to all our fields."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
